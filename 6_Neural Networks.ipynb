{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ti6RRCHDPXBi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Load"
      ],
      "metadata": {
        "id": "idHGDth0S7VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSNGjGraPihz",
        "outputId": "ace534fb-06d9-42d6-f62f-2fe1493b31f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set shape: \",x_train.shape)\n",
        "print(\"Test set shape: \",x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMWM6C-OPrL0",
        "outputId": "5d76f544-3535-492a-b4d5-bd117e837ec3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape:  (60000, 28, 28)\n",
            "Test set shape:  (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 2\n",
        "columns = 5\n",
        "\n",
        "fig, axs = plt.subplots(rows, columns, figsize=(10, 4))\n",
        "\n",
        "for i in range(10):\n",
        "    y_ids = y_train == i\n",
        "    img = random.choice(x_train[y_ids])\n",
        "\n",
        "    row = i // columns\n",
        "    col = i % columns\n",
        "\n",
        "    axs[row, col].imshow(img)\n",
        "    axs[row, col].axis('off')  # Turn off axis\n",
        "    axs[row, col].set_title(f'Digit {i}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "bYN-EgKJP73S",
        "outputId": "90a81c50-02ad-45a7-ae42-126f302ee0e7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R859JbuwRFj1",
        "outputId": "3272a9e6-91e4-440b-a44e-3bc2452d866f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digit images seem of nice quality and the classes are balanced"
      ],
      "metadata": {
        "id": "iVu1Yw__RZ1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "9SDrD3flS-8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flat = x_train.reshape(60000, 784)\n",
        "x_test_flat = x_test.reshape(10000, 784)\n",
        "\n",
        "print(\"Flat Train set shape:\", x_train_flat.shape)\n",
        "print(\"Flat Test set shape:\", x_test_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2WEip2USNVB",
        "outputId": "88250cd4-2d5a-4088-a5f6-bec2b4ecd99f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat Train set shape: (60000, 784)\n",
            "Flat Test set shape: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_flat_scaled = scaler.fit_transform(x_train_flat)\n",
        "x_test_flat_scaled = scaler.transform(x_test_flat)"
      ],
      "metadata": {
        "id": "BFc3ORDHT4iv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Layer Perceptron Classifier"
      ],
      "metadata": {
        "id": "QMvnn1ryTCx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(random_state=0)\n",
        "\n",
        "mlp.fit(x_train_flat, y_train)"
      ],
      "metadata": {
        "id": "o3Lc_DrCSqB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp.predict(x_test_flat)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLZ2G3z0TkaT",
        "outputId": "9a98acc0-5753-4212-b140-ecffd560e8f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9645\n",
            "F1 Score: 0.9644953532388295\n",
            "Precision: 0.9647081848282716\n",
            "Recall: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP Classifier with normalized values**"
      ],
      "metadata": {
        "id": "1rLDlLGyUf4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(random_state=0)\n",
        "\n",
        "mlp.fit(x_train_flat_scaled, y_train)\n",
        "\n",
        "y_pred = mlp.predict(x_test_flat_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FmPA6yDT8Pe",
        "outputId": "bdc5b48d-fcde-477e-a342-74a14677de72"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9743\n",
            "F1 Score: 0.9743014315186483\n",
            "Precision: 0.9743177627161999\n",
            "Recall: 0.9743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalized values produce slightly better results (+1 p.p.)"
      ],
      "metadata": {
        "id": "4XoBMd6-UzsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLPClassifier Parameters"
      ],
      "metadata": {
        "id": "YYU2MI-2Vm5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When configuring a neural network using the MLPClassifier there are several parameters to consider. Here are some of the key parameters:\n",
        "\n",
        "- **hidden_layer_sizes**: This parameter determines the size and number of hidden layers in the neural network. For example, hidden_layer_sizes=(5, 2) means 2 hidden layers with 5 neurons. default=(100,) which is 1 layer of 100 neurons\n",
        "\n",
        "- **activation**: Defines the activation function for the hidden layers. Common choices include 'relu' (default), 'tanh', and 'logistic'.\n",
        "\n",
        "- **solver**: The solver for weight optimization. Common options are 'adam' (default), 'sgd', and 'lbfgs'\n",
        "\n",
        "- **alpha**: It helps to avoid overfitting by penalizing large weights\n",
        "\n",
        "- **batch_size**: Size of minibatches for stochastic optimizers. This is the number of samples per gradient update. If set to 'auto', batch_size=min(200, n_samples).\n",
        "\n",
        "- **learning_rate**: Only used when solver='sgd'. Determines the learning rate schedule. Options include 'constant' (default), 'invscaling', and 'adaptive'\n",
        "\n",
        "- **learning_rate_init**: The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
        "\n",
        "- **max_iter**: Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations.\n",
        "\n",
        "- **random_state**: Determines random number generation for weights and bias initialization, which ensures reproducibility of results.\n",
        "\n",
        "- **tol**: Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
        "\n",
        "- **validation_fraction**: The proportion of training data to set aside as validation set for early stopping."
      ],
      "metadata": {
        "id": "DUOcvxWIVpXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Classifier"
      ],
      "metadata": {
        "id": "mgqL49w3YNvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = int(np.sqrt(x_train_flat.shape[0]))\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors, random_state=0)\n",
        "\n",
        "knn.fit(x_train_flat, y_train)\n",
        "\n",
        "y_pred_knn = knn.predict(x_test_flat)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "f1 = f1_score(y_test, y_pred_knn, average='weighted')\n",
        "precision = precision_score(y_test, y_pred_knn, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_knn, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqDBBNTQYQEO",
        "outputId": "ac8fcbbb-8ee2-425d-f280-ace3e7865065"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9241\n",
            "F1 Score: 0.9241202371130496\n",
            "Precision: 0.92873147144498\n",
            "Recall: 0.9241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN produces 4p.p. less accuracy accross all metrics (non normalized values)**"
      ],
      "metadata": {
        "id": "iwW6ut8UchGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction\n",
        "\n",
        "Dimensionality reduction technique like Principal Component Analysis (PCA) could be beneficial when applied.\n",
        "- It can greatly reduce the computational cost, leading to faster processing.\n",
        "- It can recuce noise\n",
        "- Help with visualization"
      ],
      "metadata": {
        "id": "Si2jDPi1dmR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.90)  # Keep 90% of variance\n",
        "\n",
        "x_train_pca = pca.fit_transform(x_train_flat_scaled)\n",
        "x_test_pca = pca.transform(x_test_flat_scaled)"
      ],
      "metadata": {
        "id": "AH37G-bNdn1G"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(random_state=0)\n",
        "\n",
        "mlp.fit(x_train_pca, y_train)\n",
        "\n",
        "y_pred = mlp.predict(x_test_pca)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBwAAZq4d284",
        "outputId": "e27d6383-5cb0-419c-a1fa-edfbb8a98568"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.973\n",
            "F1 Score: 0.9730041913268737\n",
            "Precision: 0.9730337011957272\n",
            "Recall: 0.973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping 90% of the original variance leads to almost the same scores (-0.1 p.p) and a slight increase of +0.1 p.p. when keeping the 95% of the variance! This may show successful noise reduction but the metric scores are too similar"
      ],
      "metadata": {
        "id": "te9Phu55e2NM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequantial MLP"
      ],
      "metadata": {
        "id": "EOweMtrWfXNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train_one_hot = tf.one_hot(y_train, depth=num_classes)\n",
        "y_test_one_hot = tf.one_hot(y_test, depth=num_classes)\n",
        "y_train_one_hot.shape, y_test_one_hot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGFVk22ofcEA",
        "outputId": "c393f58a-2831-44ff-af44-e5a05e40d41c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([60000, 10]), TensorShape([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (784,)\n",
        "num_hidden_layers = 2\n",
        "units_per_layer = 128\n",
        "activation = 'relu'\n",
        "\n",
        "mlp = tf.keras.Sequential(name='my-mlp')\n",
        "mlp.add(tf.keras.layers.Input(input_shape, name='input_layer'))\n",
        "for i in range(num_hidden_layers):\n",
        "  mlp.add(tf.keras.layers.Dense(units=128, activation=activation, name=f'hidden_layer_{i+1}'))\n",
        "mlp.add(tf.keras.layers.Dense(units=num_classes, activation='softmax', name='output_layer'))\n",
        "mlp.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWB7CToLfsSL",
        "outputId": "f811e7da-5392-4d3f-b6e9-c58c17246e82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my-mlp\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "mlp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=metrics)\n",
        "mlp.fit(x_train_flat, y_train_one_hot, batch_size=batch_size, epochs=epochs, validation_data=(x_test_flat, y_test_one_hot))\n",
        "\n",
        "end_time = time.perf_counter()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Execution time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0-y_21khVed",
        "outputId": "df006ed8-46ca-4efa-e660-2b10d26fe861"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 14s 5ms/step - loss: 1.7465 - accuracy: 0.8732 - val_loss: 0.4532 - val_accuracy: 0.9108\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3340 - accuracy: 0.9277 - val_loss: 0.2430 - val_accuracy: 0.9439\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2101 - accuracy: 0.9467 - val_loss: 0.1984 - val_accuracy: 0.9493\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1612 - accuracy: 0.9557 - val_loss: 0.1877 - val_accuracy: 0.9492\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1505 - accuracy: 0.9588 - val_loss: 0.1865 - val_accuracy: 0.9503\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1334 - accuracy: 0.9624 - val_loss: 0.1957 - val_accuracy: 0.9490\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1216 - accuracy: 0.9652 - val_loss: 0.1510 - val_accuracy: 0.9642\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1127 - accuracy: 0.9693 - val_loss: 0.1641 - val_accuracy: 0.9651\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1061 - accuracy: 0.9713 - val_loss: 0.1604 - val_accuracy: 0.9629\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0993 - accuracy: 0.9731 - val_loss: 0.1768 - val_accuracy: 0.9605\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0948 - accuracy: 0.9743 - val_loss: 0.1679 - val_accuracy: 0.9632\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0895 - accuracy: 0.9760 - val_loss: 0.1493 - val_accuracy: 0.9641\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0848 - accuracy: 0.9776 - val_loss: 0.1396 - val_accuracy: 0.9699\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0798 - accuracy: 0.9787 - val_loss: 0.1853 - val_accuracy: 0.9687\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0793 - accuracy: 0.9797 - val_loss: 0.2171 - val_accuracy: 0.9663\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0742 - accuracy: 0.9808 - val_loss: 0.1633 - val_accuracy: 0.9677\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0718 - accuracy: 0.9814 - val_loss: 0.2071 - val_accuracy: 0.9623\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.1787 - val_accuracy: 0.9702\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0649 - accuracy: 0.9830 - val_loss: 0.1924 - val_accuracy: 0.9690\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0719 - accuracy: 0.9824 - val_loss: 0.1944 - val_accuracy: 0.9710\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0597 - accuracy: 0.9849 - val_loss: 0.1886 - val_accuracy: 0.9698\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0716 - accuracy: 0.9834 - val_loss: 0.1659 - val_accuracy: 0.9719\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0617 - accuracy: 0.9857 - val_loss: 0.1988 - val_accuracy: 0.9709\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0576 - accuracy: 0.9855 - val_loss: 0.2255 - val_accuracy: 0.9686\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0590 - accuracy: 0.9856 - val_loss: 0.2036 - val_accuracy: 0.9693\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0607 - accuracy: 0.9862 - val_loss: 0.1894 - val_accuracy: 0.9692\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0670 - accuracy: 0.9857 - val_loss: 0.2338 - val_accuracy: 0.9708\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0678 - accuracy: 0.9859 - val_loss: 0.2254 - val_accuracy: 0.9710\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0509 - accuracy: 0.9885 - val_loss: 0.2538 - val_accuracy: 0.9677\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 0.2946 - val_accuracy: 0.9640\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0572 - accuracy: 0.9870 - val_loss: 0.2041 - val_accuracy: 0.9699\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0545 - accuracy: 0.9872 - val_loss: 0.2107 - val_accuracy: 0.9738\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0546 - accuracy: 0.9878 - val_loss: 0.2957 - val_accuracy: 0.9692\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0518 - accuracy: 0.9887 - val_loss: 0.2581 - val_accuracy: 0.9715\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0560 - accuracy: 0.9883 - val_loss: 0.2599 - val_accuracy: 0.9702\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0434 - accuracy: 0.9892 - val_loss: 0.2283 - val_accuracy: 0.9743\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0510 - accuracy: 0.9893 - val_loss: 0.2951 - val_accuracy: 0.9732\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0551 - accuracy: 0.9889 - val_loss: 0.2619 - val_accuracy: 0.9742\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0513 - accuracy: 0.9888 - val_loss: 0.2981 - val_accuracy: 0.9716\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0474 - accuracy: 0.9892 - val_loss: 0.2890 - val_accuracy: 0.9701\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0512 - accuracy: 0.9896 - val_loss: 0.3141 - val_accuracy: 0.9676\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0460 - accuracy: 0.9898 - val_loss: 0.2757 - val_accuracy: 0.9696\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0553 - accuracy: 0.9884 - val_loss: 0.2860 - val_accuracy: 0.9732\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0484 - accuracy: 0.9897 - val_loss: 0.2540 - val_accuracy: 0.9713\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0473 - accuracy: 0.9897 - val_loss: 0.2611 - val_accuracy: 0.9724\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0501 - accuracy: 0.9894 - val_loss: 0.2719 - val_accuracy: 0.9681\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0458 - accuracy: 0.9901 - val_loss: 0.2948 - val_accuracy: 0.9682\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0542 - accuracy: 0.9890 - val_loss: 0.2740 - val_accuracy: 0.9736\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0456 - accuracy: 0.9901 - val_loss: 0.3917 - val_accuracy: 0.9675\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0498 - accuracy: 0.9899 - val_loss: 0.3454 - val_accuracy: 0.9734\n",
            "Execution time: 383.248261316 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Log\n",
        "\n",
        "Execution time (CPU): 503.2487058309998 seconds\n",
        "\n",
        "Execution time (GPU): 383.248261316 seconds\n"
      ],
      "metadata": {
        "id": "YuE3ADRuqiK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "jZyvs3d1u1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_conv_layers = 2\n",
        "num_filters = 64\n",
        "kernel_size = (5,5)\n",
        "strides = (1,1)\n",
        "mlp_num_hidden_layers = 2\n",
        "mlp_units_per_layer = 128\n",
        "activation = 'relu'\n",
        "drouput_rate = 0.4\n",
        "\n",
        "x_train_cnn = np.reshape(x_train, (x_train.shape[0],28,28,1))\n",
        "x_test_cnn = np.reshape(x_test, (x_test.shape[0],28,28,1))\n",
        "\n",
        "cnn = tf.keras.Sequential(name='my-cnn')\n",
        "cnn.add(tf.keras.layers.Input((28,28,1),name='input_layer'))\n",
        "\n",
        "for i in range(num_conv_layers):\n",
        "  cnn.add(\n",
        "      tf.keras.layers.Conv2D(\n",
        "          filters=num_filters,\n",
        "          kernel_size=kernel_size,\n",
        "          strides=strides,\n",
        "          activation=activation,\n",
        "          name=f'conv_layer_{i+1}'\n",
        "      )\n",
        "  )\n",
        "  cnn.add(tf.keras.layers.Dropout(rate=0.4, name=f'drouput_{i+1}'))\n",
        "  cnn.add(tf.keras.layers.MaxPooling2D(name=f'maxpool_{i+1}'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "for i in range(mlp_num_hidden_layers):\n",
        "  cnn.add(tf.keras.layers.Dense(units=mlp_units_per_layer, activation=activation,name=f'hidden_layer_{i+1}'))\n",
        "cnn.add(tf.keras.layers.Dense(units=num_classes, activation='softmax',name='output_layer'))\n",
        "\n",
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8PB6ngvu3XO",
        "outputId": "a66255cb-5b69-4991-bda6-f3bb17dd594d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my-cnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_layer_1 (Conv2D)       (None, 24, 24, 64)        1664      \n",
            "                                                                 \n",
            " drouput_1 (Dropout)         (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " conv_layer_2 (Conv2D)       (None, 8, 8, 64)          102464    \n",
            "                                                                 \n",
            " drouput_2 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " hidden_layer_1 (Dense)      (None, 128)               131200    \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 253130 (988.79 KB)\n",
            "Trainable params: 253130 (988.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=metrics)\n",
        "cnn.fit(x_train_cnn, y_train_one_hot, batch_size=batch_size, epochs=epochs, validation_data=(x_test_cnn, y_test_one_hot))\n",
        "\n",
        "end_time = time.perf_counter()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Execution time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8WbD40WyX5f",
        "outputId": "53ae269a-00ad-4a0b-a5c4-feb17dceed5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 19s 6ms/step - loss: 0.3892 - accuracy: 0.9332 - val_loss: 0.0754 - val_accuracy: 0.9791\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1009 - accuracy: 0.9704 - val_loss: 0.0685 - val_accuracy: 0.9845\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0877 - accuracy: 0.9757 - val_loss: 0.0703 - val_accuracy: 0.9847\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0782 - accuracy: 0.9780 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.0509 - val_accuracy: 0.9883\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.0533 - val_accuracy: 0.9860\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.0537 - val_accuracy: 0.9863\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0529 - accuracy: 0.9858 - val_loss: 0.0483 - val_accuracy: 0.9885\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0571 - accuracy: 0.9853 - val_loss: 0.0554 - val_accuracy: 0.9881\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0496 - accuracy: 0.9875 - val_loss: 0.0444 - val_accuracy: 0.9908\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0475 - accuracy: 0.9884 - val_loss: 0.0373 - val_accuracy: 0.9926\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0487 - accuracy: 0.9879 - val_loss: 0.0437 - val_accuracy: 0.9913\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0434 - accuracy: 0.9893 - val_loss: 0.0354 - val_accuracy: 0.9916\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0419 - accuracy: 0.9903 - val_loss: 0.0347 - val_accuracy: 0.9919\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.0375 - val_accuracy: 0.9916\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0406 - accuracy: 0.9903 - val_loss: 0.0384 - val_accuracy: 0.9910\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0406 - accuracy: 0.9909 - val_loss: 0.0528 - val_accuracy: 0.9895\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0414 - accuracy: 0.9908 - val_loss: 0.0346 - val_accuracy: 0.9931\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0446 - accuracy: 0.9909 - val_loss: 0.0459 - val_accuracy: 0.9894\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0422 - accuracy: 0.9908 - val_loss: 0.0438 - val_accuracy: 0.9904\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0444 - accuracy: 0.9904 - val_loss: 0.0358 - val_accuracy: 0.9928\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0459 - accuracy: 0.9912 - val_loss: 0.0631 - val_accuracy: 0.9885\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0450 - accuracy: 0.9911 - val_loss: 0.0388 - val_accuracy: 0.9922\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0410 - accuracy: 0.9919 - val_loss: 0.0377 - val_accuracy: 0.9921\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0402 - accuracy: 0.9927 - val_loss: 0.0442 - val_accuracy: 0.9909\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0392 - accuracy: 0.9920 - val_loss: 0.0413 - val_accuracy: 0.9913\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0494 - accuracy: 0.9906 - val_loss: 0.0566 - val_accuracy: 0.9901\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0472 - accuracy: 0.9916 - val_loss: 0.0439 - val_accuracy: 0.9908\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0459 - accuracy: 0.9918 - val_loss: 0.0513 - val_accuracy: 0.9897\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0443 - accuracy: 0.9915 - val_loss: 0.0430 - val_accuracy: 0.9920\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0486 - accuracy: 0.9917 - val_loss: 0.0447 - val_accuracy: 0.9933\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0460 - accuracy: 0.9912 - val_loss: 0.0496 - val_accuracy: 0.9891\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0426 - accuracy: 0.9922 - val_loss: 0.0612 - val_accuracy: 0.9892\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0499 - accuracy: 0.9909 - val_loss: 0.0524 - val_accuracy: 0.9905\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0487 - accuracy: 0.9917 - val_loss: 0.0721 - val_accuracy: 0.9823\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0488 - accuracy: 0.9911 - val_loss: 0.0458 - val_accuracy: 0.9916\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0632 - accuracy: 0.9901 - val_loss: 0.0665 - val_accuracy: 0.9875\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0620 - accuracy: 0.9901 - val_loss: 0.0600 - val_accuracy: 0.9896\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0423 - accuracy: 0.9926 - val_loss: 0.0470 - val_accuracy: 0.9901\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0506 - accuracy: 0.9912 - val_loss: 0.0454 - val_accuracy: 0.9893\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0631 - accuracy: 0.9895 - val_loss: 0.0396 - val_accuracy: 0.9922\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0513 - accuracy: 0.9915 - val_loss: 0.0718 - val_accuracy: 0.9867\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0659 - accuracy: 0.9877 - val_loss: 0.0746 - val_accuracy: 0.9818\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0634 - accuracy: 0.9884 - val_loss: 0.0495 - val_accuracy: 0.9901\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0784 - accuracy: 0.9877 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0617 - accuracy: 0.9900 - val_loss: 0.0395 - val_accuracy: 0.9897\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0610 - accuracy: 0.9899 - val_loss: 0.0582 - val_accuracy: 0.9914\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0577 - accuracy: 0.9892 - val_loss: 0.0618 - val_accuracy: 0.9885\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0545 - accuracy: 0.9903 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0704 - accuracy: 0.9866 - val_loss: 0.0569 - val_accuracy: 0.9884\n",
            "Execution time: 498.0316503260001 seconds\n"
          ]
        }
      ]
    }
  ]
}